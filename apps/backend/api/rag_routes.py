"""
RAG Integration Routes for Home Inspection System
Provides endpoints for camera photo analysis with RAG system integration
"""

from fastapi import APIRouter, HTTPException, Depends
from pydantic import BaseModel
from typing import List, Dict, Any, Optional
from sqlalchemy.orm import Session
import requests
import json
import os
import base64
from datetime import datetime

from database.connection import get_db
from utils.context_injection import build_sensor_context

router = APIRouter(prefix="/api/rag", tags=["RAG"])


class PhotoAnalysisRequest(BaseModel):
    photo: str  # Base64 encoded image
    query: str
    component: str = "visual_inspection"
    location: str = "current_location"
    windowSec: int = 300


class RealtimeStreamRequest(BaseModel):
    frame: str  # Base64 encoded frame
    streamType: str = "realtime_inspection"
    location: str = "current_inspection_site"
    timestamp: str
    quality: str = "medium"


class DocumentResult(BaseModel):
    title: str
    content: str
    relevance: float
    category: str
    location: Optional[str] = None
    component: Optional[str] = None


class RAGAnalysisResponse(BaseModel):
    query: str
    relevantDocuments: List[DocumentResult]
    sensorContext: Dict[str, Any]
    recommendations: List[str]
    combinedContext: str
    timestamp: str


class RealtimeStreamResponse(BaseModel):
    frameAnalysis: Dict[str, Any]
    ragContext: Dict[str, Any]
    timestamp: str


@router.post("/analyze-photo", response_model=RAGAnalysisResponse)
async def analyze_photo_with_rag(
    request: PhotoAnalysisRequest,
    db: Session = Depends(get_db)
):
    """
    Analyze a photo using RAG system with home inspection documents
    and sensor data
    """
    try:
        # Get sensor context
        sensor_context = build_sensor_context(
            component=request.component,
            location_prefix=request.location,
            window_sec=request.windowSec,
            db=db
        )

        # Prepare RAG query with photo and sensor context
        rag_query = {
            "query": request.query,
            "photo": request.photo,
            "component": request.component,
            "location": request.location,
            "sensor_context": sensor_context,
            "timestamp": datetime.utcnow().isoformat()
        }

        # Call RAG service (assuming it's running on port 3001)
        try:
            rag_response = requests.post(
                "http://localhost:3001/api/rag/analyze",
                json=rag_query,
                timeout=30
            )

            if rag_response.status_code == 200:
                rag_data = rag_response.json()

                # Format response
                response = RAGAnalysisResponse(
                    query=request.query,
                    relevantDocuments=[
                        DocumentResult(
                            title=doc.get("title", ""),
                            content=doc.get("content", ""),
                            relevance=doc.get("relevance", 0.0),
                            category=doc.get("category", ""),
                            location=doc.get("location"),
                            component=doc.get("component")
                        )
                        for doc in rag_data.get("documents", [])
                    ],
                    sensorContext=sensor_context,
                    recommendations=rag_data.get("recommendations", []),
                    combinedContext=rag_data.get("combined_context", ""),
                    timestamp=datetime.utcnow().isoformat()
                )

                return response
            else:
                raise HTTPException(
                    status_code=rag_response.status_code,
                    detail=f"RAG service error: {rag_response.text}"
                )

        except requests.exceptions.RequestException:
            # Fallback: return basic analysis without RAG service
            return create_fallback_analysis(request, sensor_context)

    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"Photo analysis failed: {str(e)}"
        )


def create_fallback_analysis(
    request: PhotoAnalysisRequest,
    sensor_context: List[Dict]
) -> RAGAnalysisResponse:
    """
    Create a fallback analysis when RAG service is not available
    """
    # Basic sensor-based recommendations
    recommendations = []

    if sensor_context:
        # Analyze sensor data for recommendations
        for reading in sensor_context:
            if (reading.get("type") == "moisture_level" and
                    reading.get("value", 0) > 70):
                recommendations.append("æª¢æ¸¬åˆ°é«˜æ¿•åº¦ï¼Œå»ºè­°æª¢æŸ¥é€šé¢¨å’Œé˜²æ°´")
            elif (reading.get("type") == "co2" and
                  reading.get("value", 0) > 1000):
                recommendations.append("CO2æ¿ƒåº¦åé«˜ï¼Œå»ºè­°æ”¹å–„é€šé¢¨")
            elif (reading.get("type") == "temperature" and
                  reading.get("value", 0) > 30):
                recommendations.append("æº«åº¦åé«˜ï¼Œå»ºè­°æª¢æŸ¥éš”ç†±å’Œé€šé¢¨")

    if not recommendations:
        recommendations.append("å»ºè­°é€²è¡Œå°ˆæ¥­æª¢æŸ¥ä»¥ç¢ºä¿å®‰å…¨")

    # Create basic context
    combined_context = f"""
# æ”åƒé ­æª¢æŸ¥åˆ†æ
æŸ¥è©¢: {request.query}
æ™‚é–“: {datetime.utcnow().isoformat()}
çµ„ä»¶: {request.component}
ä½ç½®: {request.location}

## æ„Ÿæ‡‰å™¨æ•¸æ“š
{json.dumps(sensor_context, indent=2, ensure_ascii=False)}

## å»ºè­°
{chr(10).join(f"- {rec}" for rec in recommendations)}

æ³¨æ„: RAG æœå‹™æš«æ™‚ä¸å¯ç”¨ï¼Œé€™æ˜¯åŸºæ–¼æ„Ÿæ‡‰å™¨æ•¸æ“šçš„åŸºæœ¬åˆ†æã€‚
    """.strip()

    return RAGAnalysisResponse(
        query=request.query,
        relevantDocuments=[],
        sensorContext={"readings": sensor_context},
        recommendations=recommendations,
        combinedContext=combined_context,
        timestamp=datetime.utcnow().isoformat()
    )


@router.get("/health")
async def rag_health_check():
    """
    Check RAG service health
    """
    try:
        # Check if RAG service is running
        response = requests.get("http://localhost:3001/health", timeout=5)
        if response.status_code == 200:
            return {"status": "healthy", "rag_service": "connected"}
        else:
            return {"status": "degraded", "rag_service": "unavailable"}
    except Exception:
        return {"status": "degraded", "rag_service": "unavailable"}


@router.post("/analyze-realtime-stream", response_model=RealtimeStreamResponse)
async def analyze_realtime_stream(
    request: RealtimeStreamRequest,
    db: Session = Depends(get_db)
):
    """
    Analyze real-time camera stream frames using RAG system
    """
    try:
        # Get sensor context for real-time analysis
        sensor_context = build_sensor_context(
            component="realtime_inspection",
            location_prefix=request.location,
            window_sec=60,  # 1 minute window for real-time
            db=db
        )

        # Prepare RAG query for real-time stream analysis
        rag_query = {
            "query": f"å¯¦æ™‚æª¢æŸ¥åˆ†æ - {request.streamType}",
            "frame": request.frame,
            "streamType": request.streamType,
            "location": request.location,
            "timestamp": request.timestamp,
            "quality": request.quality,
            "sensor_context": sensor_context,
            "analysis_type": "realtime_stream"
        }

        # For real-time streaming, use OpenAI Vision API directly (skip RAG service)
        # This provides faster, more reliable analysis for live camera streams
        result = create_realtime_fallback_analysis(request, sensor_context)
        
        # Auto-create training data for learning (background task)
        # This will be processed by cleaning service later
        try:
            from services.data_cleaning_service import DataCleaningService
            # Note: Training data creation happens when issues are created
            # This is handled in issue creation flow
        except Exception as e:
            print(f"âš ï¸  Could not trigger learning data collection: {e}")
        
        return result
            
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"Real-time stream analysis failed: {str(e)}"
        )


def analyze_image_with_openai(frame_base64: str, db: Session = None) -> Dict[str, Any]:
    """
    Analyze image using OpenAI Vision API
    Uses optimized prompt from latest trained model if available
    """
    openai_api_key = os.getenv("OPENAI_API_KEY")
    if not openai_api_key:
        return None

    try:
        # Get latest optimized prompt if available
        prompt_template = None
        if db:
            try:
                from models.model_version import ModelVersion
                from sqlalchemy import and_
                latest_model = db.query(ModelVersion).filter(
                    and_(
                        ModelVersion.model_type == "detection",
                        ModelVersion.deployed == True
                    )
                ).order_by(ModelVersion.id.desc()).first()
                
                if latest_model and latest_model.prompt_template:
                    prompt_template = latest_model.prompt_template
            except Exception as e:
                print(f"âš ï¸  Could not load optimized prompt: {e}")
        
        # Use optimized prompt or fallback to default
        if not prompt_template:
            prompt_template = """è«‹ä»”ç´°åˆ†æé€™å¼µæˆ¿å±‹æª¢æŸ¥ç…§ç‰‡ï¼Œç‰¹åˆ¥æ³¨æ„æª¢æ¸¬ä»¥ä¸‹å•é¡Œï¼š

1. æ¼æ°´å•é¡Œï¼ˆæœ€é«˜å„ªå…ˆç´šï¼‰ï¼š
   - æ°´æ¼¬ã€æ°´ç—•ã€æ°´å°
   - ç‰†å£æˆ–å¤©èŠ±æ¿çš„è®Šè‰²ï¼ˆé»ƒè‰²ã€æ£•è‰²ï¼‰
   - ç©æ°´ã€æ»´æ°´ã€æ»²æ¼è·¡è±¡
   - ç®¡é“å‘¨åœçš„æ¿•æ½¤æˆ–è…è•
   - åœ°é¢ä¸Šçš„æ°´è·¡
   
2. çµæ§‹å•é¡Œï¼š
   - è£‚ç¸«ã€æå£ã€è®Šå½¢
   - ç‰†å£ä¸å¹³æ•´
   
3. æ¿•åº¦å•é¡Œï¼š
   - é»´èŒã€ç™¼éœ‰è·¡è±¡
   - æ½®æ¿•ã€éœ‰å‘³è·¡è±¡
   
4. ç®¡é“å•é¡Œï¼š
   - æ´©æ¼ã€è…è•ã€å µå¡è·¡è±¡
   - ç®¡é“é€£æ¥è™•çš„å•é¡Œ
   
5. é›»æ°£å•é¡Œï¼š
   - é›»ç·šæš´éœ²ã€é¢æ¿å•é¡Œ
   
6. å±‹é ‚å•é¡Œï¼š
   - æå£ã€ç¼ºå¤±ã€è€åŒ–
   
7. å…¶ä»–å®‰å…¨éš±æ‚£

**é‡è¦æç¤º**ï¼š
- å³ä½¿å•é¡Œçœ‹èµ·ä¾†å¾ˆå°ï¼Œä¹Ÿæ‡‰è©²æª¢æ¸¬å‡ºä¾†
- å°æ–¼æ˜é¡¯çš„å•é¡Œï¼ˆå¦‚æ¼æ°´ã€æ°´æ¼¬ï¼‰ï¼Œseverity å¿…é ˆè¨­ç‚º "high"
- å¦‚æœçœ‹åˆ°ä»»ä½•æ°´è·¡ã€è®Šè‰²æˆ–æ½®æ¿•è·¡è±¡ï¼Œå¿…é ˆæ¨™è¨˜ç‚ºæ¼æ°´å•é¡Œ
- ç‰¹åˆ¥æ³¨æ„ç‰†è§’ã€ç‰†å£é€£æ¥è™•ã€å¤©èŠ±æ¿é‚Šç·£ç­‰å®¹æ˜“æ¼æ°´çš„å€åŸŸ
- å¦‚æœç…§ç‰‡ä¸­æœ‰å…©è™•æˆ–æ›´å¤šåœ°æ–¹å‡ºç¾æ¼æ°´è·¡è±¡ï¼Œå¿…é ˆç‚ºæ¯ä¸€è™•å–®ç¨å‰µå»ºä¸€å€‹å•é¡Œæ¢ç›®

è«‹ä»¥ JSON æ ¼å¼è¿”å›ï¼ŒåŒ…å«ï¼š
- detected_issues: æª¢æ¸¬åˆ°çš„å•é¡Œåˆ—è¡¨ï¼Œæ¯å€‹å•é¡Œå¿…é ˆåŒ…å«ï¼š
  * type: å•é¡Œé¡å‹ï¼ˆå¦‚ "æ¼æ°´"ã€"çµæ§‹å•é¡Œ"ç­‰ï¼‰
  * severity: "high"ï¼ˆåš´é‡ï¼Œéœ€è¦ç«‹å³è™•ç†ï¼‰ã€"medium"ï¼ˆä¸­ç­‰ï¼‰ã€"low"ï¼ˆè¼•å¾®ï¼‰
  * description: è©³ç´°æè¿°å•é¡Œçš„ä½ç½®å’Œç‹€æ³
  * recommendation: å…·é«”çš„è§£æ±ºå»ºè­°
- overall_assessment: æ•´é«”è©•ä¼°
- confidence: åˆ†æä¿¡å¿ƒåº¦ (0-1)

å¦‚æœæ²’æœ‰æª¢æ¸¬åˆ°ä»»ä½•å•é¡Œï¼Œè¿”å›ç©ºåˆ—è¡¨ []ã€‚å¦‚æœæª¢æ¸¬åˆ°å•é¡Œï¼Œå¿…é ˆåœ¨ detected_issues ä¸­åŒ…å«è©³ç´°ä¿¡æ¯ã€‚"""
        
        # Use OpenAI Vision API to analyze the image
        response = requests.post(
            "https://api.openai.com/v1/chat/completions",
            headers={
                "Authorization": f"Bearer {openai_api_key}",
                "Content-Type": "application/json"
            },
            json={
                "model": os.getenv("OPENAI_VISION_MODEL", "gpt-4o-mini"),  # Default to gpt-4o-mini for cost optimization
                "messages": [
                    {
                        "role": "user",
                        "content": [
                            {
                                "type": "text",
                                "text": prompt_template
                            },
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:image/jpeg;base64,{frame_base64}"
                                }
                            }
                        ]
                    }
                ],
                "max_tokens": 2000,  # Increased to ensure complete analysis for multiple issues
                "temperature": 0.3  # Lower temperature for more focused detection
            },
            timeout=60  # Increased timeout for better reliability
        )

        if response.status_code == 200:
            result = response.json()
            content = result["choices"][0]["message"]["content"]
            
            # Try to parse JSON from response
            try:
                # Extract JSON from markdown code blocks if present
                import re
                json_match = re.search(r'\{.*\}', content, re.DOTALL)
                if json_match:
                    analysis_data = json.loads(json_match.group())
                    # Validate that we have detected_issues
                    if "detected_issues" in analysis_data:
                        issues_count = len(analysis_data.get("detected_issues", []))
                        print(f"âœ… Successfully parsed JSON with {issues_count} issue(s)")
                        if issues_count == 0:
                            print(f"âš ï¸  Warning: JSON parsed but detected_issues is empty")
                        return analysis_data
                    else:
                        print(f"âš ï¸  JSON parsed but no detected_issues field found, attempting text extraction")
                        # Fall through to text extraction
                else:
                    # Fallback: parse as plain JSON
                    analysis_data = json.loads(content)
                    if "detected_issues" in analysis_data:
                        issues_count = len(analysis_data.get("detected_issues", []))
                        print(f"âœ… Successfully parsed plain JSON with {issues_count} issue(s)")
                        return analysis_data
                    else:
                        print(f"âš ï¸  Plain JSON parsed but no detected_issues field found, attempting text extraction")
                        # Fall through to text extraction
            except json.JSONDecodeError as e:
                # If not JSON, try to extract issues from text
                print(f"âš ï¸  JSON parsing failed, attempting text extraction: {e}")
                print(f"ğŸ“„ Content preview: {content[:500]}...")
                
                # Try to extract issues from text description
                detected_issues = []
                if content:
                    # Look for leak-related keywords in Chinese and English
                    leak_keywords = ['æ¼æ°´', 'æ°´æ¼¬', 'æ°´ç—•', 'æ°´å°', 'è®Šè‰²', 'æ½®æ¿•', 'leak', 'water', 'stain', 'moisture', 'æ»²æ¼', 'æ¿•æ½¤', 'æ°´è·¡', 'water stain', 'water damage']
                    issue_keywords = ['å•é¡Œ', 'issue', 'problem', 'damage', 'æå£', 'è£‚ç¸«', 'crack']
                    
                    content_lower = content.lower()
                    has_leak_indicators = any(keyword.lower() in content_lower for keyword in leak_keywords)
                    
                    if has_leak_indicators or any(keyword in content for keyword in issue_keywords):
                        # Create issue from text analysis
                        detected_issues.append({
                            "type": "æ¼æ°´å•é¡Œ" if has_leak_indicators else "æ½›åœ¨å•é¡Œ",
                            "severity": "high" if has_leak_indicators else "medium",
                            "description": content[:500] if len(content) > 500 else content,
                            "recommendation": "å»ºè­°ç«‹å³æª¢æŸ¥ä¸¦ä¿®å¾©æ¼æ°´å•é¡Œã€‚è«‹è¯ç¹«å°ˆæ¥­æ°´é›»å·¥é€²è¡Œè©³ç´°æª¢æŸ¥ã€‚" if has_leak_indicators else "å»ºè­°é€²è¡Œå°ˆæ¥­æª¢æŸ¥ä»¥ç¢ºå®šå•é¡Œçš„åš´é‡ç¨‹åº¦ã€‚"
                        })
                        print(f"âœ… Extracted issue from text: {detected_issues[0]['type']}")
                
                return {
                    "detected_issues": detected_issues,
                    "overall_assessment": content,
                    "confidence": 0.6  # Lower confidence for text-based extraction
                }
        else:
            print(f"OpenAI API error: {response.status_code} - {response.text}")
            return None

    except Exception as e:
        print(f"OpenAI Vision API error: {str(e)}")
        return None


def create_realtime_fallback_analysis(
    request: RealtimeStreamRequest,
    sensor_context: List[Dict]
) -> RealtimeStreamResponse:
    """
    Create fallback analysis for real-time stream when RAG service is unavailable
    Uses OpenAI Vision API if available, otherwise falls back to sensor-based analysis
    """
    issues = []
    recommendations = []
    
    # Try to analyze image with OpenAI Vision API
    frame_base64 = request.frame
    image_analysis = None
    
    if frame_base64:
        # Pass db session to use optimized prompt
        from database.connection import SessionLocal
        db_session = SessionLocal()
        try:
            image_analysis = analyze_image_with_openai(frame_base64, db_session)
        finally:
            db_session.close()
    
    if image_analysis:
        # Use OpenAI analysis results
        detected_issues = image_analysis.get("detected_issues", [])
        for issue in detected_issues:
            issues.append({
                "type": issue.get("type", "æœªçŸ¥å•é¡Œ"),
                "severity": issue.get("severity", "medium"),
                "description": issue.get("description", "æª¢æ¸¬åˆ°æ½›åœ¨å•é¡Œ"),
                "recommendation": issue.get("recommendation", "å»ºè­°é€²è¡Œå°ˆæ¥­æª¢æŸ¥")
            })
            if issue.get("recommendation"):
                recommendations.append(issue["recommendation"])
    else:
        # Fallback: Analyze based on sensor data
        if sensor_context:
            for reading in sensor_context:
                if (reading.get("type") == "moisture_level" and
                        reading.get("value", 0) > 70):
                    issues.append({
                        "type": "é«˜æ¿•åº¦æª¢æ¸¬",
                        "severity": "high",
                        "description": f"æª¢æ¸¬åˆ°é«˜æ¿•åº¦: {reading.get('value')}%",
                        "recommendation": "å»ºè­°æª¢æŸ¥é€šé¢¨å’Œé˜²æ°´ç³»çµ±"
                    })
                    recommendations.append("ç«‹å³æª¢æŸ¥æ¿•åº¦ä¾†æºä¸¦æ”¹å–„é€šé¢¨")
                
                elif (reading.get("type") == "co2" and
                      reading.get("value", 0) > 1000):
                    issues.append({
                        "type": "ç©ºæ°£å“è³ªå•é¡Œ",
                        "severity": "medium",
                        "description": f"CO2æ¿ƒåº¦åé«˜: {reading.get('value')}ppm",
                        "recommendation": "å»ºè­°æ”¹å–„é€šé¢¨ç³»çµ±"
                    })
                    recommendations.append("æª¢æŸ¥é€šé¢¨ç³»çµ±æ˜¯å¦æ­£å¸¸é‹ä½œ")
                
                elif (reading.get("type") == "temperature" and
                      reading.get("value", 0) > 30):
                    issues.append({
                        "type": "æº«åº¦ç•°å¸¸",
                        "severity": "medium",
                        "description": f"æº«åº¦åé«˜: {reading.get('value')}Â°C",
                        "recommendation": "æª¢æŸ¥éš”ç†±å’Œé€šé¢¨ç³»çµ±"
                    })
                    recommendations.append("æª¢æŸ¥éš”ç†±ææ–™å’Œé€šé¢¨ç‹€æ³")

    # Build frame analysis with actual results
    frame_analysis = {
        "issues": issues,
        "detected_issues": issues,
        "detectedProblems": issues,
        "image_analysis_used": image_analysis is not None,
        "analysis_status": "completed",
        "analysis_method": "openai_vision" if image_analysis else "sensor_fallback"
    }
    
    # Add OpenAI analysis results if available
    if image_analysis:
        frame_analysis["overall_assessment"] = image_analysis.get("overall_assessment", "")
        frame_analysis["confidence"] = image_analysis.get("confidence", 0.7)
        frame_analysis["analysis_summary"] = image_analysis.get("overall_assessment", "å·²å®Œæˆåœ–åƒåˆ†æ")
        
        # Only add objects if OpenAI actually detected them (not hardcoded)
        if "detected_objects" in image_analysis:
            frame_analysis["objects"] = image_analysis["detected_objects"]
        elif "objects" in image_analysis:
            frame_analysis["objects"] = image_analysis["objects"]
        else:
            # No objects detected, don't add empty array
            frame_analysis["objects"] = []
    else:
        # No OpenAI analysis, use sensor-based fallback
        frame_analysis["overall_assessment"] = "åŸºæ–¼å‚³æ„Ÿå™¨æ•¸æ“šçš„åˆ†æ"
        frame_analysis["confidence"] = 0.6
        frame_analysis["analysis_summary"] = "ä½¿ç”¨å‚³æ„Ÿå™¨æ•¸æ“šé€²è¡Œåˆ†æ"
        frame_analysis["objects"] = []

    # Create RAG context
    rag_context = {
        "relevantDocuments": [
            {
                "title": "å¯¦æ™‚æª¢æŸ¥æŒ‡å—",
                "content": "åŸºæ–¼åœ–åƒåˆ†æå’Œæ„Ÿæ‡‰å™¨æ•¸æ“šçš„å¯¦æ™‚æª¢æŸ¥å»ºè­°",
                "relevance": 0.9
            }
        ],
        "sensorData": sensor_context,
        "recommendations": recommendations,
        "imageAnalysis": image_analysis.get("overall_assessment", "") if image_analysis else None
    }

    return RealtimeStreamResponse(
        frameAnalysis=frame_analysis,
        ragContext=rag_context,
        timestamp=datetime.utcnow().isoformat()
    )


@router.get("/documents/count")
async def get_document_count():
    """
    Get count of documents in RAG system
    """
    try:
        response = requests.get(
            "http://localhost:3001/api/documents/count",
            timeout=10
        )
        if response.status_code == 200:
            return response.json()
        else:
            return {"count": 0, "error": "RAG service unavailable"}
    except Exception:
        return {"count": 0, "error": "RAG service unavailable"}